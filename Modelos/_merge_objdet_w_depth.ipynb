{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f44a8d6-5821-422b-a9ee-496e91d32a1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47f45024-0220-499c-a4f5-cc797d7362ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    \"save_pth\": \"checkpoint/\",\n",
    "    \"reg_max\": 4,\n",
    "}\n",
    "params['device'] = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1485888e-2a41-44e9-a2b8-a20dcf94569a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e673505b-8ba8-4089-aa83-1d8e2434e273",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    \"\"\" \n",
    "    Convolutional block composed of conv->batchnorm->relu. \n",
    "    \"\"\"\n",
    "    def __init__(self, cin=1, cout=1, k=1, s=1, p=0, device='cpu'):\n",
    "        super(ConvModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, (k, k), stride=s, padding=p, bias=False).to(device)\n",
    "        self.bn = nn.BatchNorm2d(cout, eps=0.001, momentum=0.03, affine=True, track_running_stats=True).to(device)\n",
    "        self.silu = nn.SiLU(inplace=True).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.silu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bd9f5fb0-ec74-47fd-ae27-d67d7a2d53f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\" \n",
    "    Bottleneck block componsed of conv->conv->residual connection. \n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, shortcut=False, device='cpu'):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = ConvModule(cin=c, cout=c//2, k=3, s=1, p=1, device=device)\n",
    "        self.conv2 = ConvModule(cin=c//2, cout=c, k=3, s=1, p=1, device=device)\n",
    "        self.shortcut = shortcut\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xin = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.shortcut==True:\n",
    "            x = xin + x\n",
    "            return x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c02252d-f88e-4549-a87f-f75fd99ce83a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class C2f(nn.Module):\n",
    "    \"\"\" \n",
    "    C2f module (cross-stage partial bottleneck with two convolutions) which combines \n",
    "    high-level features with contextual information to improve detection accuracy. \n",
    "    \"\"\"\n",
    "    def __init__(self, cin=1, cout=1, depth=1, device='cpu'):\n",
    "        super(C2f, self).__init__()\n",
    "        self.cout = cout\n",
    "        self.depth = depth\n",
    "        self.convmodule1 = ConvModule(cin=cin, cout=cout, k=1, s=1, p=0, device=device)\n",
    "        self.bottleneck = []\n",
    "        for _ in range(depth):\n",
    "            self.bottleneck.append(Bottleneck(c=self.cout//2, shortcut=True, device=device))\n",
    "        cin = cout//2 * (depth+2)\n",
    "        self.convmodule2 = ConvModule(cin=cin, cout=cout, k=1, s=1, p=0, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.convmodule1(x)\n",
    "        x1_1, x1_2 = torch.split(x1, self.cout//2, dim=1)\n",
    "        x3 = torch.cat([x1_1, x1_2],dim=1)\n",
    "        for i in range(len(self.bottleneck)):\n",
    "            x2 = self.bottleneck[i](x1_2)\n",
    "            x3 = torch.cat([x3, x2], dim=1)\n",
    "            x1_2 = x2\n",
    "        x = self.convmodule2(x3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31dad4e4-794c-47a2-af82-77ae25093a37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SPPF(nn.Module):\n",
    "    \"\"\" \n",
    "    Spatial pyramid pooling fast module (SPPF) layer accelerates computation \n",
    "    by pooling features into a fixed-size map. \n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, device='cpu'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = ConvModule(cin=c, cout=c, k=1, s=1, p=0, device=device)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.conv2 = ConvModule(cin=c*4, cout=c, k=1, s=1, p=0, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x1 = self.mp1(x)\n",
    "        x2 = self.mp2(x1)\n",
    "        x3 = self.mp3(x2)\n",
    "        x = torch.cat([x, x1, x2, x3], dim=1)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5dc8136a-7c2f-4e6c-bbbe-7d8939ae0c07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Detection head module, which is decoupled to regression, classification, \n",
    "    and depth central pixel estimation tasks independently.\n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, reg_max=1, nclass=1, device='cpu'):\n",
    "        super(DetectionHead, self).__init__()\n",
    "        d = max(c, reg_max*4)\n",
    "        self.bboxconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.bboxconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.bboxconv3 = nn.Conv2d(d, 4*reg_max, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "        self.clsconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.clsconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.clsconv3 = nn.Conv2d(d, nclass, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "        self.dptconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.dptconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.dptconv3 = nn.Conv2d(d, 1, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # bbox branch\n",
    "        xbbox = self.bboxconv1(x)\n",
    "        xbbox = self.bboxconv2(xbbox)\n",
    "        xbbox = self.bboxconv3(xbbox)\n",
    "        # cls branch\n",
    "        xcls = self.clsconv1(x)\n",
    "        xcls = self.clsconv2(xcls)\n",
    "        xcls = self.clsconv3(xcls)\n",
    "        # depth branch\n",
    "        xdpt = self.dptconv1(x)\n",
    "        xdpt = self.dptconv2(xdpt)\n",
    "        xdpt = self.dptconv3(xdpt)\n",
    "        \n",
    "        feats = torch.cat([xbbox, xcls, xdpt], dim=1) \n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c108d49a-7f89-44b6-9861-6830614cea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DFL(nn.Module):\n",
    "    \"\"\"\n",
    "    Integral module of Distribution Focal Loss (DFL).\n",
    "    Proposed in Generalized Focal Loss https://ieeexplore.ieee.org/document/9792391\n",
    "    \"\"\"\n",
    "    def __init__(self, c1=16, device='cpu'):\n",
    "        \"\"\"Initialize a convolutional layer with a given number of input channels.\"\"\"\n",
    "        super(DFL, self).__init__()\n",
    "        self.conv = nn.Conv2d(c1, 1, 1, bias=False).requires_grad_(False).to(device)\n",
    "        x = torch.arange(c1, dtype=torch.float)\n",
    "        self.conv.weight.data[:] = nn.Parameter(x.view(1, c1, 1, 1))\n",
    "        self.c1 = c1\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Applies a transformer layer on input tensor 'x' and returns a tensor.\"\"\"\n",
    "        b, c, a = x.shape  # batch, channels, anchors\n",
    "        return self.conv(x.view(b, 4, self.c1, a).transpose(2, 1).softmax(1)).view(b, 4, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d880edc5-fb46-4957-a204-2a08bf8c0f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inference(nn.Module):\n",
    "    def __init__(self, nclasses=1, stride=None, reg_max=1, device='cpu'):\n",
    "        super(Inference, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.nc = nclasses\n",
    "        self.reg_max = reg_max\n",
    "        self.no = self.reg_max*4 + nclasses + 1\n",
    "        self.dfl = DFL(self.reg_max, device=device) #if self.reg_max > 1 else nn.Identity()\n",
    "        \n",
    "    def forward(self, feats):\n",
    "        # Extract predictions from each head at different strides\n",
    "        pred_distri, pred_scores, pred_depth = torch.cat([xi.view(feats[0].shape[0], self.no, -1) for xi in feats], 2).split((self.reg_max*4, self.nc, 1), 1)\n",
    "        pred_scores = pred_scores.permute(0, 1, 2).contiguous() # (b, nc, h*w)\n",
    "        pred_distri = pred_distri.permute(0, 1, 2).contiguous() # (b, 4*reg_max, h*w)\n",
    "        pred_depth = pred_depth.permute(0, 1, 2).contiguous() # (b, 1, h*w)\n",
    "        # Get anchor point centers from output grids and its corresponding stride\n",
    "        anchors, strides = (x.transpose(0, 1) for x in self.make_anchors(feats, self.stride, 0.5))\n",
    "        # Decode reg_max*4 prediction to cxywh bounding box prediction\n",
    "        dbox = self.dist2bbox(self.dfl(pred_distri), anchors.unsqueeze(0), xywh=True, dim=1).clamp_(0.) * strides\n",
    "        y = torch.cat((dbox, pred_scores.sigmoid(), pred_depth), 1) # (bs, 4 + nclasses + depth, h*w)\n",
    "        return y\n",
    "    \n",
    "    def dist2bbox(self, distance, anchor_points, xywh=True, dim=-1):\n",
    "        \"\"\"Transform distance(ltrb) to box(xywh or xyxy).\n",
    "                width and height of bounding box are in range [0, 2*(self.reg_max-1)] owing to (x2y2-x1y1=rb+lt) \n",
    "        \"\"\"\n",
    "        lt, rb = distance.chunk(2, dim) # lt and rb is in range[0, self.reg_max-1] \n",
    "        x1y1 = anchor_points - lt\n",
    "        x2y2 = anchor_points + rb\n",
    "        if xywh:\n",
    "            c_xy = (x1y1 + x2y2) / 2\n",
    "            wh = x2y2 - x1y1\n",
    "            return torch.cat((c_xy, wh), dim)  # xywh bbox\n",
    "        return torch.cat((x1y1, x2y2), dim)  # xyxy bbox\n",
    "\n",
    "    def make_anchors(self, feats, strides, grid_cell_offset=0.5):\n",
    "        \"\"\"Generate anchors from features.\"\"\"\n",
    "        anchor_points, stride_tensor = [], []\n",
    "        assert feats is not None\n",
    "        dtype, device = feats[0].dtype, feats[0].device\n",
    "        for i, stride in enumerate(strides):\n",
    "            _, _, h, w = feats[i].shape\n",
    "            sx = torch.arange(end=w, device=device, dtype=dtype) + grid_cell_offset  # shift x\n",
    "            sy = torch.arange(end=h, device=device, dtype=dtype) + grid_cell_offset  # shift y\n",
    "            sy, sx = torch.meshgrid(sy, sx, indexing='ij')\n",
    "            anchor_points.append(torch.stack((sx, sy), -1).view(-1, 2))\n",
    "            stride_tensor.append(torch.full((h * w, 1), stride, dtype=dtype, device=device))\n",
    "        return torch.cat(anchor_points), torch.cat(stride_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b08a0dd4-7b6e-4c8c-a6a3-fcb6485d7fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Object Detection model inspired on YOLOv8 from Ultralytics (https://docs.ultralytics.com/models/yolov8/#supported-tasks).\n",
    "    The features maps has been divided by two respect the nano version, \n",
    "    in order to reduce model size for edge devices.\n",
    "    The detection head incorportes a new feature: a decoupled head for \n",
    "    depth estimation of the central pixel of the regressed bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        nclasses (int): number of classes in the classification task of bounding boxes.\n",
    "        device (string): device to initiate and proccess weights; cpu or cuda.\n",
    "    \n",
    "    Attributes:\n",
    "        convX (nn.Conv2d): two dimensional convolution layer to extract features along\n",
    "                           different resolution maps.\n",
    "        sppf (nn.Module): spatial pyramid pooling fast module.\n",
    "        c2f_x (nn.Module): cross-stage partial bottleneck module.\n",
    "        upsample (nn.Upsample): upsampling layer to concatenate features in the neck \n",
    "                                control connections.\n",
    "        headX (nn.Module): detection head for different features resolution maps.\n",
    "        \n",
    "    Methods:\n",
    "        forward(self, x): forward given input along detection model.\n",
    "    \"\"\"\n",
    "    def __init__(self, nclasses=1, reg_max=1, device='cpu'):\n",
    "        super(ObjectDetector, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvModule(cin=3, cout=16, k=3, s=2, p=1, device=device)\n",
    "        self.conv2 = ConvModule(cin=16, cout=32, k=3, s=2, p=1, device=device)\n",
    "        self.conv3 = ConvModule(cin=32, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv4 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv5 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv6 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv7 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        \n",
    "        self.sppf = SPPF(c=64, device=device)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest').to(device)\n",
    "\n",
    "        self.c2f_1 = C2f(cin=32, cout=32, depth=1, device=device)\n",
    "        self.c2f_2 = C2f(cin=64, cout=64, depth=2, device=device)\n",
    "        self.c2f_3 = C2f(cin=64, cout=64, depth=2, device=device)\n",
    "        self.c2f_4 = C2f(cin=64, cout=64, depth=1, device=device)\n",
    "        self.c2f_5 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_6 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_7 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_8 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        \n",
    "        self.head1 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        self.head2 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        self.head3 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        \n",
    "        #self.inference = Inference(nclasses=nclasses, stride=torch.tensor([8,16,32]), reg_max=reg_max, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        ## ------------------------------ BACKBONE ------------------------------------\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        c2f_1 = self.c2f_1(x2)\n",
    "        x3 = self.conv3(c2f_1)\n",
    "        c2f_2 = self.c2f_2(x3)\n",
    "        x4 = self.conv4(c2f_2)\n",
    "        c2f_3 = self.c2f_3(x4)\n",
    "        x5 = self.conv5(c2f_3)\n",
    "        c2f_4 = self.c2f_4(x5)\n",
    "        sppf = self.sppf(c2f_4)\n",
    "        \n",
    "        ## ------------------------------ NECK ------------------------------------\n",
    "        ## process branch\n",
    "        up_1 = self.upsample(sppf)\n",
    "        cat_1 = torch.cat([up_1, c2f_3], dim=1)\n",
    "        c2f_5 = self.c2f_5(cat_1)      \n",
    "        up_2 = self.upsample(c2f_5)    \n",
    "        cat_2 = torch.cat([up_2, c2f_2], dim=1)\n",
    "        c2f_6 = self.c2f_6(cat_2)\n",
    "\n",
    "        ## error feedback branch\n",
    "        x6 = self.conv6(c2f_6)\n",
    "        cat_3 = torch.cat([x6, c2f_5], dim=1)\n",
    "        c2f_7 = self.c2f_7(cat_3)\n",
    "        x7 = self.conv7(c2f_7)\n",
    "        cat_4 = torch.cat([x7, sppf], dim=1)\n",
    "        c2f_8 = self.c2f_8(cat_4)\n",
    "    \n",
    "        ## ------------------------------ HEAD ----------------------------------\n",
    "        head1 = self.head1(c2f_6)\n",
    "        head2 = self.head2(c2f_7)\n",
    "        head3 = self.head3(c2f_8)\n",
    "        \n",
    "        head_detections = (head1, head2, head3)\n",
    "        #y = self.inference(head_detections)\n",
    "        \n",
    "        return head_detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc7b870-af8b-46de-80bc-21e1f912e858",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0869bb90-af9c-4184-b721-2f0f00d2b0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "       Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "==========================================================================\n",
      "       ConvModule-1      [1, 3, 640, 640]             464               0\n",
      "       ConvModule-2     [1, 16, 320, 320]           4,672               0\n",
      "              C2f-3     [1, 32, 160, 160]           2,688               0\n",
      "       ConvModule-4     [1, 32, 160, 160]          18,560               0\n",
      "              C2f-5       [1, 64, 80, 80]          12,544               0\n",
      "       ConvModule-6       [1, 64, 80, 80]          36,992               0\n",
      "              C2f-7       [1, 64, 40, 40]          12,544               0\n",
      "       ConvModule-8       [1, 64, 40, 40]          36,992               0\n",
      "              C2f-9       [1, 64, 20, 20]          10,496               0\n",
      "            SPPF-10       [1, 64, 20, 20]          20,736               0\n",
      "        Upsample-11       [1, 64, 20, 20]               0               0\n",
      "             C2f-12      [1, 128, 40, 40]          14,592               0\n",
      "             C2f-13      [1, 128, 80, 80]          14,592               0\n",
      "      ConvModule-14       [1, 64, 80, 80]          36,992               0\n",
      "             C2f-15      [1, 128, 40, 40]          14,592               0\n",
      "      ConvModule-16       [1, 64, 40, 40]          36,992               0\n",
      "             C2f-17      [1, 128, 20, 20]          14,592               0\n",
      "   DetectionHead-18       [1, 64, 80, 80]         228,160               0\n",
      "   DetectionHead-19       [1, 64, 40, 40]         228,160               0\n",
      "   DetectionHead-20       [1, 64, 20, 20]         228,160               0\n",
      "==========================================================================\n",
      "Total params: 973,520\n",
      "Trainable params: 0\n",
      "Non-trainable params: 973,520\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Load Object Detection Trained model\n",
    "if str(params[\"device\"]) == 'cuda':\n",
    "    trained_model = torch.load('checkpoint/coco_objdet.pt').to(params[\"device\"])\n",
    "else:\n",
    "    trained_model = torch.load('checkpoint/coco_objdet.pt', map_location=torch.device('cpu')).to(params[\"device\"])\n",
    "\n",
    "# Load Depth Estimation Trained model    \n",
    "if str(params[\"device\"]) == 'cuda':\n",
    "    dpt_model = torch.load('checkpoint/coco_depth.pt').to(params[\"device\"])\n",
    "else:\n",
    "    dpt_model = torch.load('checkpoint/coco_depth.pt', map_location=torch.device('cpu')).to(params[\"device\"])\n",
    "\n",
    "\n",
    "# Copy Depth Estimation head weights from depth model to objdet model\n",
    "trained_model.head1.dptconv1 = deepcopy(dpt_model.head1.dptconv1)\n",
    "trained_model.head1.dptconv2 = deepcopy(dpt_model.head1.dptconv2)\n",
    "trained_model.head1.dptconv3 = deepcopy(dpt_model.head1.dptconv3)\n",
    "\n",
    "trained_model.head2.dptconv1 = deepcopy(dpt_model.head2.dptconv1)\n",
    "trained_model.head2.dptconv2 = deepcopy(dpt_model.head2.dptconv2)\n",
    "trained_model.head2.dptconv3 = deepcopy(dpt_model.head2.dptconv3)\n",
    "\n",
    "trained_model.head3.dptconv1 = deepcopy(dpt_model.head3.dptconv1)\n",
    "trained_model.head3.dptconv2 = deepcopy(dpt_model.head3.dptconv2)\n",
    "trained_model.head3.dptconv3 = deepcopy(dpt_model.head3.dptconv3)\n",
    "\n",
    "del dpt_model\n",
    "\n",
    "for name, param in trained_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    #param.grad = None\n",
    "\n",
    "trained_model.eval()\n",
    "print(summary(trained_model.to(params[\"device\"]), torch.zeros((1, 3, 640, 640)).to(params[\"device\"]), show_input=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfeb7abc-0443-4699-8eb5-e000eb5496b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Correct C2F module: change a list of tensors to be a class of nn.Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "394396ba-dc3d-4289-97a6-3c3299573c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvModule(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional block composed of conv->batchnorm->relu. \n",
    "    \"\"\"\n",
    "    def __init__(self, cin=1, cout=1, k=1, s=1, p=0, device='cpu'):\n",
    "        super(ConvModule, self).__init__()\n",
    "        self.conv = nn.Conv2d(cin, cout, (k, k), stride=s, padding=p, bias=False).to(device)\n",
    "        self.bn = nn.BatchNorm2d(cout, eps=0.001, momentum=0.03, affine=True, track_running_stats=True).to(device)\n",
    "        self.silu = nn.SiLU(inplace=True).to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.silu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "430cc818-6245-4e13-be3f-7b7df4daa693",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    \"\"\" \n",
    "    Bottleneck block componsed of conv->conv->residual connection. \n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, shortcut=False, device='cpu'):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = ConvModule(cin=c, cout=c//2, k=3, s=1, p=1, device=device)\n",
    "        self.conv2 = ConvModule(cin=c//2, cout=c, k=3, s=1, p=1, device=device)\n",
    "        self.shortcut = shortcut\n",
    "        \n",
    "    def forward(self, x):\n",
    "        xin = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        if self.shortcut==True:\n",
    "            x = xin + x\n",
    "            return x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ebd7d245-5d8f-4dbc-9288-5f96ad4e593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class C2f(nn.Module):\n",
    "    \"\"\" \n",
    "    C2f module (cross-stage partial bottleneck with two convolutions) which combines \n",
    "    high-level features with contextual information to improve detection accuracy. \n",
    "    \"\"\"\n",
    "    def __init__(self, cin=1, cout=1, depth=1, device='cpu'):\n",
    "        super(C2f, self).__init__()\n",
    "        self.cout = cout\n",
    "        self.depth = depth\n",
    "        self.convmodule1 = ConvModule(cin=cin, cout=cout, k=1, s=1, p=0, device=device)\n",
    "        bottleneck = []\n",
    "        for _ in range(depth):\n",
    "            bottleneck.append(Bottleneck(c=self.cout//2, shortcut=True, device=device))\n",
    "        self.bottleneck = nn.Sequential(*bottleneck)\n",
    "        cin = cout//2 * (depth+2)\n",
    "        self.convmodule2 = ConvModule(cin=cin, cout=cout, k=1, s=1, p=0, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.convmodule1(x)\n",
    "        x1_1, x1_2 = torch.split(x1, self.cout//2, dim=1)\n",
    "        x3 = torch.cat([x1_1, x1_2],dim=1)\n",
    "        for mod in self.bottleneck:\n",
    "            x2 = mod(x1_2)\n",
    "            x3 = torch.cat([x3, x2], dim=1)\n",
    "            x1_2 = x2\n",
    "        x = self.convmodule2(x3)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb89d690-a438-4ff1-a820-a410ccae22bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SPPF(nn.Module):\n",
    "    \"\"\" \n",
    "    Spatial pyramid pooling fast module (SPPF) layer accelerates computation \n",
    "    by pooling features into a fixed-size map. \n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, device='cpu'):\n",
    "        super(SPPF, self).__init__()\n",
    "        self.conv1 = ConvModule(cin=c, cout=c, k=1, s=1, p=0, device=device)\n",
    "        self.mp1 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.mp2 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.mp3 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False).to(device)\n",
    "        self.conv2 = ConvModule(cin=c*4, cout=c, k=1, s=1, p=0, device=device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x1 = self.mp1(x)\n",
    "        x2 = self.mp2(x1)\n",
    "        x3 = self.mp3(x2)\n",
    "        x = torch.cat([x, x1, x2, x3], dim=1)\n",
    "        x = self.conv2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4b1ef125-7794-451d-88b2-52aff394d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DetectionHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Detection head module, which is decoupled to regression, classification, \n",
    "    and depth central pixel estimation tasks independently.\n",
    "    \"\"\"\n",
    "    def __init__(self, c=1, reg_max=1, nclass=1, device='cpu'):\n",
    "        super(DetectionHead, self).__init__()\n",
    "        d = max(c, reg_max*4)\n",
    "        self.bboxconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.bboxconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.bboxconv3 = nn.Conv2d(d, 4*reg_max, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "        self.clsconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.clsconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.clsconv3 = nn.Conv2d(d, nclass, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "        self.dptconv1 = ConvModule(cin=c, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.dptconv2 = ConvModule(cin=d, cout=d, k=3, s=1, p=1, device=device)\n",
    "        self.dptconv3 = nn.Conv2d(d, 1, (1, 1), stride=1, padding=0, bias=False).to(device)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        # bbox branch\n",
    "        xbbox = self.bboxconv1(x)\n",
    "        xbbox = self.bboxconv2(xbbox)\n",
    "        xbbox = self.bboxconv3(xbbox)\n",
    "        # cls branch\n",
    "        xcls = self.clsconv1(x)\n",
    "        xcls = self.clsconv2(xcls)\n",
    "        xcls = self.clsconv3(xcls)\n",
    "        # depth branch\n",
    "        xdpt = self.dptconv1(x)\n",
    "        xdpt = self.dptconv2(xdpt)\n",
    "        xdpt = self.dptconv3(xdpt)\n",
    "        \n",
    "        feats = torch.cat([xbbox, xcls, xdpt], dim=1) \n",
    "        return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8999b98a-2372-4d0b-9835-b7bd263d278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObjectDetector(nn.Module):\n",
    "    \"\"\"\n",
    "    Object Detection model inspired on YOLOv8 from Ultralytics (https://docs.ultralytics.com/models/yolov8/#supported-tasks).\n",
    "    The features maps has been divided by two respect the nano version, \n",
    "    in order to reduce model size for edge devices.\n",
    "    The detection head incorportes a new feature: a decoupled head for \n",
    "    depth estimation of the central pixel of the regressed bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        nclasses (int): number of classes in the classification task of bounding boxes.\n",
    "        device (string): device to initiate and proccess weights; cpu or cuda.\n",
    "    \n",
    "    Attributes:\n",
    "        convX (nn.Conv2d): two dimensional convolution layer to extract features along\n",
    "                           different resolution maps.\n",
    "        sppf (nn.Module): spatial pyramid pooling fast module.\n",
    "        c2f_x (nn.Module): cross-stage partial bottleneck module.\n",
    "        upsample (nn.Upsample): upsampling layer to concatenate features in the neck \n",
    "                                control connections.\n",
    "        headX (nn.Module): detection head for different features resolution maps.\n",
    "        \n",
    "    Methods:\n",
    "        forward(self, x): forward given input along detection model.\n",
    "    \"\"\"\n",
    "    def __init__(self, nclasses=1, reg_max=1, device='cpu'):\n",
    "        super(ObjectDetector, self).__init__()\n",
    "\n",
    "        self.conv1 = ConvModule(cin=3, cout=16, k=3, s=2, p=1, device=device)\n",
    "        self.conv2 = ConvModule(cin=16, cout=32, k=3, s=2, p=1, device=device)\n",
    "        self.conv3 = ConvModule(cin=32, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv4 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv5 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv6 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        self.conv7 = ConvModule(cin=64, cout=64, k=3, s=2, p=1, device=device)\n",
    "        \n",
    "        self.sppf = SPPF(c=64, device=device)\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode='nearest').to(device)\n",
    "\n",
    "        self.c2f_1 = C2f(cin=32, cout=32, depth=1, device=device)\n",
    "        self.c2f_2 = C2f(cin=64, cout=64, depth=2, device=device)\n",
    "        self.c2f_3 = C2f(cin=64, cout=64, depth=2, device=device)\n",
    "        self.c2f_4 = C2f(cin=64, cout=64, depth=1, device=device)\n",
    "        self.c2f_5 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_6 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_7 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        self.c2f_8 = C2f(cin=128, cout=64, depth=1, device=device)\n",
    "        \n",
    "        self.head1 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        self.head2 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        self.head3 = DetectionHead(c=64, reg_max=reg_max, nclass=nclasses, device=device)\n",
    "        \n",
    "        #self.inference = Inference(nclasses=nclasses, stride=torch.tensor([8,16,32]), reg_max=reg_max, device=device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        ## ------------------------------ BACKBONE ------------------------------------\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.conv2(x1)\n",
    "        c2f_1 = self.c2f_1(x2)\n",
    "        x3 = self.conv3(c2f_1)\n",
    "        c2f_2 = self.c2f_2(x3)\n",
    "        x4 = self.conv4(c2f_2)\n",
    "        c2f_3 = self.c2f_3(x4)\n",
    "        x5 = self.conv5(c2f_3)\n",
    "        c2f_4 = self.c2f_4(x5)\n",
    "        sppf = self.sppf(c2f_4)\n",
    "        \n",
    "        ## ------------------------------ NECK ------------------------------------\n",
    "        ## process branch\n",
    "        up_1 = self.upsample(sppf)\n",
    "        cat_1 = torch.cat([up_1, c2f_3], dim=1)\n",
    "        c2f_5 = self.c2f_5(cat_1)      \n",
    "        up_2 = self.upsample(c2f_5)    \n",
    "        cat_2 = torch.cat([up_2, c2f_2], dim=1)\n",
    "        c2f_6 = self.c2f_6(cat_2)\n",
    "\n",
    "        ## error feedback branch\n",
    "        x6 = self.conv6(c2f_6)\n",
    "        cat_3 = torch.cat([x6, c2f_5], dim=1)\n",
    "        c2f_7 = self.c2f_7(cat_3)\n",
    "        x7 = self.conv7(c2f_7)\n",
    "        cat_4 = torch.cat([x7, sppf], dim=1)\n",
    "        c2f_8 = self.c2f_8(cat_4)\n",
    "    \n",
    "        ## ------------------------------ HEAD ----------------------------------\n",
    "        head1 = self.head1(c2f_6)\n",
    "        head2 = self.head2(c2f_7)\n",
    "        head3 = self.head3(c2f_8)\n",
    "        \n",
    "        head_detections = (head1, head2, head3)\n",
    "        #y = self.inference(head_detections)\n",
    "        \n",
    "        return head_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fe9cd95-af06-450e-b30e-6e603087c8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------\n",
      "       Layer (type)           Input Shape         Param #     Tr. Param #\n",
      "==========================================================================\n",
      "       ConvModule-1      [1, 3, 640, 640]             464               0\n",
      "       ConvModule-2     [1, 16, 320, 320]           4,672               0\n",
      "              C2f-3     [1, 32, 160, 160]           5,040               0\n",
      "       ConvModule-4     [1, 32, 160, 160]          18,560               0\n",
      "              C2f-5       [1, 64, 80, 80]          31,168               0\n",
      "       ConvModule-6       [1, 64, 80, 80]          36,992               0\n",
      "              C2f-7       [1, 64, 40, 40]          31,168               0\n",
      "       ConvModule-8       [1, 64, 40, 40]          36,992               0\n",
      "              C2f-9       [1, 64, 20, 20]          19,808               0\n",
      "            SPPF-10       [1, 64, 20, 20]          20,736               0\n",
      "        Upsample-11       [1, 64, 20, 20]               0               0\n",
      "             C2f-12      [1, 128, 40, 40]          23,904               0\n",
      "             C2f-13      [1, 128, 80, 80]          23,904               0\n",
      "      ConvModule-14       [1, 64, 80, 80]          36,992               0\n",
      "             C2f-15      [1, 128, 40, 40]          23,904               0\n",
      "      ConvModule-16       [1, 64, 40, 40]          36,992               0\n",
      "             C2f-17      [1, 128, 20, 20]          23,904               0\n",
      "   DetectionHead-18       [1, 64, 80, 80]         228,160               0\n",
      "   DetectionHead-19       [1, 64, 40, 40]         228,160               0\n",
      "   DetectionHead-20       [1, 64, 20, 20]         228,160               0\n",
      "==========================================================================\n",
      "Total params: 1,059,680\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,059,680\n",
      "--------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "new_model = ObjectDetector(nclasses=nclasses, reg_max=params[\"reg_max\"], device=params[\"device\"])\n",
    "\n",
    "for name, param in new_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "    #param.grad = None\n",
    "\n",
    "#model.to(torch.float32).eval()\n",
    "new_model.eval()\n",
    "print(summary(new_model.to(params[\"device\"]), torch.zeros((1, 3, 640, 640)).to(params[\"device\"]), show_input=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8166d6a-c6ac-4870-b49b-dc9911238dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy all weights from model to the new model with the C2F module corrected (the arch doesnt change at all)\n",
    "\n",
    "# conv1\n",
    "new_model.conv1.conv = deepcopy(trained_model.conv1.conv)\n",
    "new_model.conv1.bn = deepcopy(trained_model.conv1.bn)\n",
    "new_model.conv1.silu = deepcopy(trained_model.conv1.silu)\n",
    "# conv2\n",
    "new_model.conv2.conv = deepcopy(trained_model.conv2.conv)\n",
    "new_model.conv2.bn = deepcopy(trained_model.conv2.bn)\n",
    "new_model.conv2.silu = deepcopy(trained_model.conv2.silu)\n",
    "# conv3\n",
    "new_model.conv3.conv = deepcopy(trained_model.conv3.conv)\n",
    "new_model.conv3.bn = deepcopy(trained_model.conv3.bn)\n",
    "new_model.conv3.silu = deepcopy(trained_model.conv3.silu)\n",
    "# conv4\n",
    "new_model.conv4.conv = deepcopy(trained_model.conv4.conv)\n",
    "new_model.conv4.bn = deepcopy(trained_model.conv4.bn)\n",
    "new_model.conv4.silu = deepcopy(trained_model.conv4.silu)\n",
    "# conv5\n",
    "new_model.conv5.conv = deepcopy(trained_model.conv5.conv)\n",
    "new_model.conv5.bn = deepcopy(trained_model.conv5.bn)\n",
    "new_model.conv5.silu = deepcopy(trained_model.conv5.silu)\n",
    "# conv6\n",
    "new_model.conv6.conv = deepcopy(trained_model.conv6.conv)\n",
    "new_model.conv6.bn = deepcopy(trained_model.conv6.bn)\n",
    "new_model.conv6.silu = deepcopy(trained_model.conv6.silu)\n",
    "# conv7\n",
    "new_model.conv7.conv = deepcopy(trained_model.conv7.conv)\n",
    "new_model.conv7.bn = deepcopy(trained_model.conv7.bn)\n",
    "new_model.conv7.silu = deepcopy(trained_model.conv7.silu)\n",
    "# spff\n",
    "new_model.sppf.conv1.conv = deepcopy(trained_model.sppf.conv1.conv)\n",
    "new_model.sppf.conv1.bn = deepcopy(trained_model.sppf.conv1.bn)\n",
    "new_model.sppf.conv1.silu = deepcopy(trained_model.sppf.conv1.silu)\n",
    "new_model.sppf.mp1 = deepcopy(trained_model.sppf.mp1)\n",
    "new_model.sppf.mp2 = deepcopy(trained_model.sppf.mp2)\n",
    "new_model.sppf.mp3 = deepcopy(trained_model.sppf.mp3)\n",
    "new_model.sppf.conv2.conv = deepcopy(trained_model.sppf.conv2.conv)\n",
    "new_model.sppf.conv2.bn = deepcopy(trained_model.sppf.conv2.bn)\n",
    "new_model.sppf.conv2.silu = deepcopy(trained_model.sppf.conv2.silu)\n",
    "# c2f modules \n",
    "# c2f_1\n",
    "new_model.c2f_1.convmodule1.conv = deepcopy(trained_model.c2f_1.convmodule1.conv)\n",
    "new_model.c2f_1.convmodule1.bn = deepcopy(trained_model.c2f_1.convmodule1.bn)\n",
    "new_model.c2f_1.convmodule1.silu = deepcopy(trained_model.c2f_1.convmodule1.silu)\n",
    "new_model.c2f_1.convmodule2.conv = deepcopy(trained_model.c2f_1.convmodule2.conv)\n",
    "new_model.c2f_1.convmodule2.bn = deepcopy(trained_model.c2f_1.convmodule2.bn)\n",
    "new_model.c2f_1.convmodule2.silu = deepcopy(trained_model.c2f_1.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_1.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_1.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_1.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_1.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_1.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_1.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_1.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_1.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_1.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_1.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_1.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_1.bottleneck[0].conv2.silu)\n",
    "# c2f_2\n",
    "new_model.c2f_2.convmodule1.conv = deepcopy(trained_model.c2f_2.convmodule1.conv)\n",
    "new_model.c2f_2.convmodule1.bn = deepcopy(trained_model.c2f_2.convmodule1.bn)\n",
    "new_model.c2f_2.convmodule1.silu = deepcopy(trained_model.c2f_2.convmodule1.silu)\n",
    "new_model.c2f_2.convmodule2.conv = deepcopy(trained_model.c2f_2.convmodule2.conv)\n",
    "new_model.c2f_2.convmodule2.bn = deepcopy(trained_model.c2f_2.convmodule2.bn)\n",
    "new_model.c2f_2.convmodule2.silu = deepcopy(trained_model.c2f_2.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_2.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_2.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_2.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_2.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_2.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_2.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_2.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_2.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_2.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_2.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_2.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_2.bottleneck[0].conv2.silu)\n",
    "\n",
    "new_model.c2f_2.bottleneck[1].conv1.conv = deepcopy(trained_model.c2f_2.bottleneck[1].conv1.conv)\n",
    "new_model.c2f_2.bottleneck[1].conv1.bn = deepcopy(trained_model.c2f_2.bottleneck[1].conv1.bn)\n",
    "new_model.c2f_2.bottleneck[1].conv1.silu = deepcopy(trained_model.c2f_2.bottleneck[1].conv1.silu)\n",
    "\n",
    "new_model.c2f_2.bottleneck[1].conv2.conv = deepcopy(trained_model.c2f_2.bottleneck[1].conv2.conv)\n",
    "new_model.c2f_2.bottleneck[1].conv2.bn = deepcopy(trained_model.c2f_2.bottleneck[1].conv2.bn)\n",
    "new_model.c2f_2.bottleneck[1].conv2.silu = deepcopy(trained_model.c2f_2.bottleneck[1].conv2.silu)\n",
    "# c2f_3\n",
    "new_model.c2f_3.convmodule1.conv = deepcopy(trained_model.c2f_3.convmodule1.conv)\n",
    "new_model.c2f_3.convmodule1.bn = deepcopy(trained_model.c2f_3.convmodule1.bn)\n",
    "new_model.c2f_3.convmodule1.silu = deepcopy(trained_model.c2f_3.convmodule1.silu)\n",
    "new_model.c2f_3.convmodule2.conv = deepcopy(trained_model.c2f_3.convmodule2.conv)\n",
    "new_model.c2f_3.convmodule2.bn = deepcopy(trained_model.c2f_3.convmodule2.bn)\n",
    "new_model.c2f_3.convmodule2.silu = deepcopy(trained_model.c2f_3.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_3.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_3.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_3.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_3.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_3.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_3.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_3.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_3.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_3.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_3.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_3.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_3.bottleneck[0].conv2.silu)\n",
    "\n",
    "new_model.c2f_3.bottleneck[1].conv1.conv = deepcopy(trained_model.c2f_3.bottleneck[1].conv1.conv)\n",
    "new_model.c2f_3.bottleneck[1].conv1.bn = deepcopy(trained_model.c2f_3.bottleneck[1].conv1.bn)\n",
    "new_model.c2f_3.bottleneck[1].conv1.silu = deepcopy(trained_model.c2f_3.bottleneck[1].conv1.silu)\n",
    "\n",
    "new_model.c2f_3.bottleneck[1].conv2.conv = deepcopy(trained_model.c2f_3.bottleneck[1].conv2.conv)\n",
    "new_model.c2f_3.bottleneck[1].conv2.bn = deepcopy(trained_model.c2f_3.bottleneck[1].conv2.bn)\n",
    "new_model.c2f_3.bottleneck[1].conv2.silu = deepcopy(trained_model.c2f_3.bottleneck[1].conv2.silu)\n",
    "# c2f_4\n",
    "new_model.c2f_4.convmodule1.conv = deepcopy(trained_model.c2f_4.convmodule1.conv)\n",
    "new_model.c2f_4.convmodule1.bn = deepcopy(trained_model.c2f_4.convmodule1.bn)\n",
    "new_model.c2f_4.convmodule1.silu = deepcopy(trained_model.c2f_4.convmodule1.silu)\n",
    "new_model.c2f_4.convmodule2.conv = deepcopy(trained_model.c2f_4.convmodule2.conv)\n",
    "new_model.c2f_4.convmodule2.bn = deepcopy(trained_model.c2f_4.convmodule2.bn)\n",
    "new_model.c2f_4.convmodule2.silu = deepcopy(trained_model.c2f_4.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_4.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_4.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_4.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_4.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_4.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_4.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_4.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_4.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_4.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_4.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_4.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_4.bottleneck[0].conv2.silu)\n",
    "# c2f_5\n",
    "new_model.c2f_5.convmodule1.conv = deepcopy(trained_model.c2f_5.convmodule1.conv)\n",
    "new_model.c2f_5.convmodule1.bn = deepcopy(trained_model.c2f_5.convmodule1.bn)\n",
    "new_model.c2f_5.convmodule1.silu = deepcopy(trained_model.c2f_5.convmodule1.silu)\n",
    "new_model.c2f_5.convmodule2.conv = deepcopy(trained_model.c2f_5.convmodule2.conv)\n",
    "new_model.c2f_5.convmodule2.bn = deepcopy(trained_model.c2f_5.convmodule2.bn)\n",
    "new_model.c2f_5.convmodule2.silu = deepcopy(trained_model.c2f_5.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_5.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_5.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_5.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_5.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_5.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_5.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_5.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_5.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_5.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_5.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_5.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_5.bottleneck[0].conv2.silu)\n",
    "# c2f_6\n",
    "new_model.c2f_6.convmodule1.conv = deepcopy(trained_model.c2f_6.convmodule1.conv)\n",
    "new_model.c2f_6.convmodule1.bn = deepcopy(trained_model.c2f_6.convmodule1.bn)\n",
    "new_model.c2f_6.convmodule1.silu = deepcopy(trained_model.c2f_6.convmodule1.silu)\n",
    "new_model.c2f_6.convmodule2.conv = deepcopy(trained_model.c2f_6.convmodule2.conv)\n",
    "new_model.c2f_6.convmodule2.bn = deepcopy(trained_model.c2f_6.convmodule2.bn)\n",
    "new_model.c2f_6.convmodule2.silu = deepcopy(trained_model.c2f_6.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_6.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_6.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_6.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_6.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_6.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_6.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_6.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_6.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_6.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_6.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_6.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_6.bottleneck[0].conv2.silu)\n",
    "# c2f_7\n",
    "new_model.c2f_7.convmodule1.conv = deepcopy(trained_model.c2f_7.convmodule1.conv)\n",
    "new_model.c2f_7.convmodule1.bn = deepcopy(trained_model.c2f_7.convmodule1.bn)\n",
    "new_model.c2f_7.convmodule1.silu = deepcopy(trained_model.c2f_7.convmodule1.silu)\n",
    "new_model.c2f_7.convmodule2.conv = deepcopy(trained_model.c2f_7.convmodule2.conv)\n",
    "new_model.c2f_7.convmodule2.bn = deepcopy(trained_model.c2f_7.convmodule2.bn)\n",
    "new_model.c2f_7.convmodule2.silu = deepcopy(trained_model.c2f_7.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_7.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_7.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_7.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_7.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_7.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_7.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_7.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_7.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_7.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_7.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_7.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_7.bottleneck[0].conv2.silu)\n",
    "# c2f_8\n",
    "new_model.c2f_8.convmodule1.conv = deepcopy(trained_model.c2f_8.convmodule1.conv)\n",
    "new_model.c2f_8.convmodule1.bn = deepcopy(trained_model.c2f_8.convmodule1.bn)\n",
    "new_model.c2f_8.convmodule1.silu = deepcopy(trained_model.c2f_8.convmodule1.silu)\n",
    "new_model.c2f_8.convmodule2.conv = deepcopy(trained_model.c2f_8.convmodule2.conv)\n",
    "new_model.c2f_8.convmodule2.bn = deepcopy(trained_model.c2f_8.convmodule2.bn)\n",
    "new_model.c2f_8.convmodule2.silu = deepcopy(trained_model.c2f_8.convmodule2.silu)\n",
    "\n",
    "new_model.c2f_8.bottleneck[0].conv1.conv = deepcopy(trained_model.c2f_8.bottleneck[0].conv1.conv)\n",
    "new_model.c2f_8.bottleneck[0].conv1.bn = deepcopy(trained_model.c2f_8.bottleneck[0].conv1.bn)\n",
    "new_model.c2f_8.bottleneck[0].conv1.silu = deepcopy(trained_model.c2f_8.bottleneck[0].conv1.silu)\n",
    "\n",
    "new_model.c2f_8.bottleneck[0].conv2.conv = deepcopy(trained_model.c2f_8.bottleneck[0].conv2.conv)\n",
    "new_model.c2f_8.bottleneck[0].conv2.bn = deepcopy(trained_model.c2f_8.bottleneck[0].conv2.bn)\n",
    "new_model.c2f_8.bottleneck[0].conv2.silu = deepcopy(trained_model.c2f_8.bottleneck[0].conv2.silu)\n",
    "# head1\n",
    "new_model.head1.bboxconv1.conv = deepcopy(trained_model.head1.bboxconv1.conv)\n",
    "new_model.head1.bboxconv1.bn = deepcopy(trained_model.head1.bboxconv1.bn)\n",
    "new_model.head1.bboxconv1.silu = deepcopy(trained_model.head1.bboxconv1.silu)\n",
    "new_model.head1.bboxconv2.conv = deepcopy(trained_model.head1.bboxconv2.conv)\n",
    "new_model.head1.bboxconv2.bn = deepcopy(trained_model.head1.bboxconv2.bn)\n",
    "new_model.head1.bboxconv2.silu = deepcopy(trained_model.head1.bboxconv2.silu)\n",
    "new_model.head1.bboxconv3 = deepcopy(trained_model.head1.bboxconv3)\n",
    "\n",
    "new_model.head1.clsconv1.conv = deepcopy(trained_model.head1.clsconv1.conv)\n",
    "new_model.head1.clsconv1.bn = deepcopy(trained_model.head1.clsconv1.bn)\n",
    "new_model.head1.clsconv1.silu = deepcopy(trained_model.head1.clsconv1.silu)\n",
    "new_model.head1.clsconv2.conv = deepcopy(trained_model.head1.clsconv2.conv)\n",
    "new_model.head1.clsconv2.bn = deepcopy(trained_model.head1.clsconv2.bn)\n",
    "new_model.head1.clsconv2.silu = deepcopy(trained_model.head1.clsconv2.silu)\n",
    "new_model.head1.clsconv3 = deepcopy(trained_model.head1.clsconv3)\n",
    "\n",
    "new_model.head1.dptconv1.conv = deepcopy(trained_model.head1.dptconv1.conv)\n",
    "new_model.head1.dptconv1.bn = deepcopy(trained_model.head1.dptconv1.bn)\n",
    "new_model.head1.dptconv1.silu = deepcopy(trained_model.head1.dptconv1.silu)\n",
    "new_model.head1.dptconv2.conv = deepcopy(trained_model.head1.dptconv2.conv)\n",
    "new_model.head1.dptconv2.bn = deepcopy(trained_model.head1.dptconv2.bn)\n",
    "new_model.head1.dptconv2.silu = deepcopy(trained_model.head1.dptconv2.silu)\n",
    "new_model.head1.dptconv3 = deepcopy(trained_model.head1.dptconv3)\n",
    "# head2\n",
    "new_model.head2.bboxconv1.conv = deepcopy(trained_model.head2.bboxconv1.conv)\n",
    "new_model.head2.bboxconv1.bn = deepcopy(trained_model.head2.bboxconv1.bn)\n",
    "new_model.head2.bboxconv1.silu = deepcopy(trained_model.head2.bboxconv1.silu)\n",
    "new_model.head2.bboxconv2.conv = deepcopy(trained_model.head2.bboxconv2.conv)\n",
    "new_model.head2.bboxconv2.bn = deepcopy(trained_model.head2.bboxconv2.bn)\n",
    "new_model.head2.bboxconv2.silu = deepcopy(trained_model.head2.bboxconv2.silu)\n",
    "new_model.head2.bboxconv3 = deepcopy(trained_model.head2.bboxconv3)\n",
    "\n",
    "new_model.head2.clsconv1.conv = deepcopy(trained_model.head2.clsconv1.conv)\n",
    "new_model.head2.clsconv1.bn = deepcopy(trained_model.head2.clsconv1.bn)\n",
    "new_model.head2.clsconv1.silu = deepcopy(trained_model.head2.clsconv1.silu)\n",
    "new_model.head2.clsconv2.conv = deepcopy(trained_model.head2.clsconv2.conv)\n",
    "new_model.head2.clsconv2.bn = deepcopy(trained_model.head2.clsconv2.bn)\n",
    "new_model.head2.clsconv2.silu = deepcopy(trained_model.head2.clsconv2.silu)\n",
    "new_model.head2.clsconv3 = deepcopy(trained_model.head2.clsconv3)\n",
    "\n",
    "new_model.head2.dptconv1.conv = deepcopy(trained_model.head2.dptconv1.conv)\n",
    "new_model.head2.dptconv1.bn = deepcopy(trained_model.head2.dptconv1.bn)\n",
    "new_model.head2.dptconv1.silu = deepcopy(trained_model.head2.dptconv1.silu)\n",
    "new_model.head2.dptconv2.conv = deepcopy(trained_model.head2.dptconv2.conv)\n",
    "new_model.head2.dptconv2.bn = deepcopy(trained_model.head2.dptconv2.bn)\n",
    "new_model.head2.dptconv2.silu = deepcopy(trained_model.head2.dptconv2.silu)\n",
    "new_model.head2.dptconv3 = deepcopy(trained_model.head2.dptconv3)\n",
    "# head3\n",
    "new_model.head3.bboxconv1.conv = deepcopy(trained_model.head3.bboxconv1.conv)\n",
    "new_model.head3.bboxconv1.bn = deepcopy(trained_model.head3.bboxconv1.bn)\n",
    "new_model.head3.bboxconv1.silu = deepcopy(trained_model.head3.bboxconv1.silu)\n",
    "new_model.head3.bboxconv2.conv = deepcopy(trained_model.head3.bboxconv2.conv)\n",
    "new_model.head3.bboxconv2.bn = deepcopy(trained_model.head3.bboxconv2.bn)\n",
    "new_model.head3.bboxconv2.silu = deepcopy(trained_model.head3.bboxconv2.silu)\n",
    "new_model.head3.bboxconv3 = deepcopy(trained_model.head3.bboxconv3)\n",
    "\n",
    "new_model.head3.clsconv1.conv = deepcopy(trained_model.head3.clsconv1.conv)\n",
    "new_model.head3.clsconv1.bn = deepcopy(trained_model.head3.clsconv1.bn)\n",
    "new_model.head3.clsconv1.silu = deepcopy(trained_model.head3.clsconv1.silu)\n",
    "new_model.head3.clsconv2.conv = deepcopy(trained_model.head3.clsconv2.conv)\n",
    "new_model.head3.clsconv2.bn = deepcopy(trained_model.head3.clsconv2.bn)\n",
    "new_model.head3.clsconv2.silu = deepcopy(trained_model.head3.clsconv2.silu)\n",
    "new_model.head3.clsconv3 = deepcopy(trained_model.head3.clsconv3)\n",
    "\n",
    "new_model.head3.dptconv1.conv = deepcopy(trained_model.head3.dptconv1.conv)\n",
    "new_model.head3.dptconv1.bn = deepcopy(trained_model.head3.dptconv1.bn)\n",
    "new_model.head3.dptconv1.silu = deepcopy(trained_model.head3.dptconv1.silu)\n",
    "new_model.head3.dptconv2.conv = deepcopy(trained_model.head3.dptconv2.conv)\n",
    "new_model.head3.dptconv2.bn = deepcopy(trained_model.head3.dptconv2.bn)\n",
    "new_model.head3.dptconv2.silu = deepcopy(trained_model.head3.dptconv2.silu)\n",
    "new_model.head3.dptconv3 = deepcopy(trained_model.head3.dptconv3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948af96-2656-4088-81ba-ee0cc5fe6668",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Save merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71ad03cb-dab7-48ad-9c89-1ebcfa71fbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save quantized model\n",
    "version = params['version']\n",
    "save_pth = os.getcwd() + '/' + params[\"save_pth\"]\n",
    "model_to_save = deepcopy(new_model.to('cpu'))\n",
    "pth = Path(save_pth + f'/DOD_coco.pt')\n",
    "torch.save(model_to_save, pth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
